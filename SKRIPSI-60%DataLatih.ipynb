{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366d3169-309f-4a97-b41b-01a3e4efbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65725da8-b095-4619-b6e4-041cd5531f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\Program_Skripsi\\Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "816d4475-2230-45a3-b1b4-e8c911e416ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = ['SBW_SB', 'SBW_B', 'SBW_K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c771e043-ae55-4357-bde6-21ea194bb772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUMLAH CLASS : 3\n",
      "----------------\n",
      "1. SBW_SB\n",
      "2. SBW_B\n",
      "1. SBW_K\n"
     ]
    }
   ],
   "source": [
    "print(f\"JUMLAH CLASS : {len(new_classes)}\")\n",
    "print(\"----------------\") \n",
    "print(f\"1. {new_classes[0]}\")\n",
    "print(f\"2. {new_classes[1]}\")\n",
    "print(f\"1. {new_classes[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4393f0-3873-4a05-87a5-65a0b49dd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e349e8c7-6cab-4af4-ac14-1afab41639c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\Program_Skripsi\\\\Dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\Program_Skripsi\\\\Dataset'"
     ]
    }
   ],
   "source": [
    "dataset = os.path.join(path)\n",
    "print(os.listdir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37001b2-5a5f-477f-81e3-e68e0e01fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBW_SB\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\Program_Skripsi\\\\Dataset\\\\SBW_SB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      7\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, images[z])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\Program_Skripsi\\\\Dataset\\\\SBW_SB'"
     ]
    }
   ],
   "source": [
    "for x in new_classes:\n",
    "    path = os.path.join(dataset, x)\n",
    "    print(x)\n",
    "    print(\"-------------------------------\")\n",
    "    images = os.listdir(path)\n",
    "    for z in range(2):\n",
    "        img_path = os.path.join(path, images[z])\n",
    "        img = Image.open(img_path)\n",
    "        print(f\"{z+1}. Size Gambar : {img.size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ecc2f2a-0950-4a16-aa58-8f44f62e7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_baru = 'D:\\\\Program_Skripsi\\\\Split Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7418fa76-6aee-4379-806c-54a35280dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for cls in new_classes:\n",
    "#     os.makedirs(path_baru + '\\\\Training Data\\\\' + cls)\n",
    "#     os.makedirs(path_baru + '\\\\Validation Data\\\\' + cls)\n",
    "#     os.makedirs(path_baru + '\\\\Test Data\\\\' + cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a125881-8c9f-46a0-930f-7ede898f3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import shutil\n",
    "\n",
    "# for cls in new_classes:\n",
    "#     category_path = os.path.join(path, cls)\n",
    "#     print(category_path)\n",
    "\n",
    "#     all_dataset = os.listdir(category_path)\n",
    "#     np.random.shuffle(all_dataset)\n",
    "\n",
    "#     # Menghitung indeks untuk split\n",
    "#     train_idx = int(len(all_dataset) * 0.70)\n",
    "#     val_idx = int(len(all_dataset) * 0.90)  # 70% + 20% = 90%\n",
    "\n",
    "#     # Membagi dataset\n",
    "#     split_train, split_val, split_test = np.split(\n",
    "#         np.array(all_dataset),\n",
    "#         [train_idx, val_idx]\n",
    "#     )\n",
    "    \n",
    "#     print(f\"\\n{cls}\")\n",
    "#     print(f\"--------------------------\")\n",
    "#     print(f\"Total Images      :  {len(all_dataset)}\")\n",
    "#     print(f\"Total Training    :  {len(split_train)}\")\n",
    "#     print(f\"Total Validation  :  {len(split_val)}\")\n",
    "#     print(f\"Total Testing     :  {len(split_test)}\\n\")\n",
    "\n",
    "#     # Menambahkan path pada setiap file\n",
    "#     split_train = [temp + '\\\\' + name for name in split_train]\n",
    "#     split_val = [temp + '\\\\' + name for name in split_val]\n",
    "#     split_test = [temp + '\\\\' + name for name in split_test]\n",
    "    \n",
    "#     # Menyalin file ke folder tujuan\n",
    "#     for name in split_train:\n",
    "#         shutil.copy(name, path_baru + '\\\\Training Data\\\\' + cls)\n",
    "    \n",
    "#     for name in split_val:\n",
    "#         shutil.copy(name, path_baru + '\\\\Validation Data\\\\' + cls)\n",
    "    \n",
    "#     for name in split_test:\n",
    "#         shutil.copy(name, path_baru + '\\\\Testing Data\\\\' + cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e26025-9ebc-4e3a-bbd3-a2294d8ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Program_Skripsi\\Dataset'\n",
    "train_dir = r'D:\\Program_Skripsi\\Split Dataset\\Training Data'\n",
    "valid_dir = r'D:\\Program_Skripsi\\Split Dataset\\Validation Data'\n",
    "test_dir = r'D:\\Program_Skripsi\\Split Dataset\\Testing Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dab061b0-c87c-4e31-bdea-6ed0cd17cd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: D:\\PROGRAM\\Dataset\\SBW_SB\n",
      "Directories created for SBW_SB:\n",
      "Train: D:\\PROGRAM\\Split Dataset\\Training Data\\SBW_SB\n",
      "Valid: D:\\PROGRAM\\Split Dataset\\Validation Data\\SBW_SB\n",
      "Test: D:\\PROGRAM\\Split Dataset\\Testing Data\\SBW_SB\n",
      "Dataset split completed for 'SBW_SB'.\n",
      "Processing category: D:\\PROGRAM\\Dataset\\SBW_B\n",
      "Directories created for SBW_B:\n",
      "Train: D:\\PROGRAM\\Split Dataset\\Training Data\\SBW_B\n",
      "Valid: D:\\PROGRAM\\Split Dataset\\Validation Data\\SBW_B\n",
      "Test: D:\\PROGRAM\\Split Dataset\\Testing Data\\SBW_B\n",
      "Dataset split completed for 'SBW_B'.\n",
      "Processing category: D:\\PROGRAM\\Dataset\\SBW_K\n",
      "Directories created for SBW_K:\n",
      "Train: D:\\PROGRAM\\Split Dataset\\Training Data\\SBW_K\n",
      "Valid: D:\\PROGRAM\\Split Dataset\\Validation Data\\SBW_K\n",
      "Test: D:\\PROGRAM\\Split Dataset\\Testing Data\\SBW_K\n",
      "Dataset split completed for 'SBW_K'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Membaca semua subfolder (misalnya 'normal', 'abnormal')\n",
    "categories = os.listdir(path)\n",
    "\n",
    "# Memproses setiap kategori (subfolder)\n",
    "for category in new_classes:\n",
    "    category_path = os.path.join(path, category)\n",
    "\n",
    "    # Debug jalur\n",
    "    print(f\"Processing category: {category_path}\")\n",
    "\n",
    "    if os.path.isdir(category_path):  # Cek jika direktori\n",
    "        all_images = os.listdir(category_path)\n",
    "\n",
    "        # Tangani kategori dengan data kecil\n",
    "        if len(all_images) < 3:\n",
    "            print(f\"Skipping category '{category}' due to insufficient data ({len(all_images)} images).\")\n",
    "            continue\n",
    "\n",
    "        # Split data\n",
    "        train_images, temp_images = train_test_split(all_images, test_size=0.3, random_state=42)\n",
    "        valid_images, test_images = train_test_split(temp_images, test_size=0.333, random_state=42)\n",
    "\n",
    "        # Buat subfolder\n",
    "        train_subdir = os.path.join(train_dir, category)\n",
    "        valid_subdir = os.path.join(valid_dir, category)\n",
    "        test_subdir = os.path.join(test_dir, category)\n",
    "\n",
    "        os.makedirs(train_subdir, exist_ok=True)\n",
    "        os.makedirs(valid_subdir, exist_ok=True)\n",
    "        os.makedirs(test_subdir, exist_ok=True)\n",
    "\n",
    "        # Debug pembuatan direktori\n",
    "        print(f\"Directories created for {category}:\")\n",
    "        print(f\"Train: {train_subdir}\")\n",
    "        print(f\"Valid: {valid_subdir}\")\n",
    "        print(f\"Test: {test_subdir}\")\n",
    "\n",
    "        # Copy files\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(category_path, img), os.path.join(train_subdir, img))\n",
    "        for img in valid_images:\n",
    "            shutil.copy(os.path.join(category_path, img), os.path.join(valid_subdir, img))\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(category_path, img), os.path.join(test_subdir, img))\n",
    "\n",
    "        print(f\"Dataset split completed for '{category}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9696a253-5cf7-4947-ad1d-40173dd933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path ke dataset\n",
    "train_dir = \"D:\\PROGRAM\\Split Dataset\\Training Data\"\n",
    "valid_dir = \"D:\\PROGRAM\\Split Dataset\\Validation Data\"\n",
    "\n",
    "# Ukuran gambar dan batch size\n",
    "img_height, img_width = 224, 224  # Meningkatkan ukuran gambar\n",
    "batch_size = 32  # Mengurangi batch size untuk stabilitas pelatihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7dc59a4-000d-4011-a8a7-f756d9691a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m save_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(img_name)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Nama file dasar\u001b[39;00m\n\u001b[0;32m     35\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m augmentor\u001b[38;5;241m.\u001b[39mflow(\n\u001b[0;32m     37\u001b[0m     img_array,\n\u001b[0;32m     38\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     39\u001b[0m     save_to_dir\u001b[38;5;241m=\u001b[39maugmented_category_path,\n\u001b[0;32m     40\u001b[0m     save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m     41\u001b[0m     save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     42\u001b[0m ):\n\u001b[0;32m     43\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m:  \u001b[38;5;66;03m# Augmentasi hingga 10 gambar\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:801\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    799\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n\u001b[0;32m    800\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 801\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[0;32m    805\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2013\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   2010\u001b[0m img_col_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2011\u001b[0m img_channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2013\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2030\u001b[0m     x \u001b[38;5;241m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   2031\u001b[0m         x,\n\u001b[0;32m   2032\u001b[0m         transform_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2033\u001b[0m         img_channel_axis,\n\u001b[0;32m   2034\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2615\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   2612\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2613\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m-> 2615\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2616\u001b[0m     ndimage\u001b[38;5;241m.\u001b[39minterpolation\u001b[38;5;241m.\u001b[39maffine_transform(\n\u001b[0;32m   2617\u001b[0m         x_channel,\n\u001b[0;32m   2618\u001b[0m         final_affine_matrix,\n\u001b[0;32m   2619\u001b[0m         final_offset,\n\u001b[0;32m   2620\u001b[0m         order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   2621\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfill_mode,\n\u001b[0;32m   2622\u001b[0m         cval\u001b[38;5;241m=\u001b[39mcval,\n\u001b[0;32m   2623\u001b[0m     )\n\u001b[0;32m   2624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m   2625\u001b[0m ]\n\u001b[0;32m   2626\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2627\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2612\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2613\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2615\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 2616\u001b[0m     \u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2620\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m   2625\u001b[0m ]\n\u001b[0;32m   2626\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2627\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:611\u001b[0m, in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    608\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[38;5;241m/\u001b[39mmatrix, output, order,\n\u001b[0;32m    609\u001b[0m                          mode, cval, npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometric_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "\n",
    "# Direktori input dan output\n",
    "input_dir = train_dir  # Direktori asal\n",
    "output_dir = input_dir  # Direktori penyimpanan hasil augmentasi\n",
    "\n",
    "# Pastikan direktori output ada\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ImageDataGenerator untuk augmentasi\n",
    "augmentor = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.5,  # Gunakan titik desimal\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=45,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "# Augmentasi 10 kali lipat\n",
    "for category in os.listdir(input_dir):  # Iterasi per kelas\n",
    "    category_path = os.path.join(input_dir, category)\n",
    "    augmented_category_path = os.path.join(output_dir, category)\n",
    "    os.makedirs(augmented_category_path, exist_ok=True)\n",
    "\n",
    "    for img_name in os.listdir(category_path):  # Iterasi per gambar\n",
    "        img_path = os.path.join(category_path, img_name)\n",
    "        img = load_img(img_path)  # Membaca gambar\n",
    "        img_array = img_to_array(img)  # Mengonversi ke array\n",
    "        img_array = img_array.reshape((1,) + img_array.shape)  # Ubah dimensi untuk generator\n",
    "\n",
    "        # Generator untuk augmentasi\n",
    "        save_prefix = os.path.splitext(img_name)[0]  # Nama file dasar\n",
    "        i = 0\n",
    "        for batch in augmentor.flow(\n",
    "            img_array,\n",
    "            batch_size=1,\n",
    "            save_to_dir=augmented_category_path,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format='jpg'\n",
    "        ):\n",
    "            i += 1\n",
    "            if i >= 10:  # Augmentasi hingga 10 gambar\n",
    "                break\n",
    "\n",
    "    print(f\"Augmentasi untuk kelas '{category}' selesai.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86aedca-3fdc-44c3-b7c3-404dd7be5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    " valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data training\n",
    "train_data = augmentor.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',  # Menggunakan RGB\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Data validasi\n",
    "val_data = valid_datagen.flow_from_directory(\n",
    "    directory=valid_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',  # Menggunakan RGB\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13541e-aed9-4fe6-b43e-bf9118427bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Mengambil batch pertama dari generator\n",
    "images, labels = train_data.next()\n",
    "\n",
    "for i in range(8):  # Menampilkan 8 gambar\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    plt.imshow(images[i])  # Menampilkan gambar\n",
    "    label_idx = np.argmax(labels[i])  # Mendapatkan indeks label (untuk categorical)\n",
    "    plt.title(categories[label_idx])  # Menampilkan nama kategori\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ff365-b5d8-4508-b85a-bc3c80968cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan VGG16 sebagai base model\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet',  # Pre-trained weights dari ImageNet\n",
    "    include_top=False,   # Menghapus fully connected layer terakhir\n",
    "    input_shape=(img_height, img_width, 3)  # Input shape untuk RGB\n",
    ")\n",
    "\n",
    "# Membekukan beberapa layer terakhir dari base model untuk fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-2]:  # Membekukan lebih sedikit layer\n",
    "    layer.trainable = False\n",
    "\n",
    "# Menambahkan fully connected layers di atas base model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),  # Flatten output convolusi\n",
    "    layers.Dense(128, activation='relu'),  # Fully connected layer\n",
    "    layers.Dropout(0.3),  # Mengurangi dropout\n",
    "    layers.Dense(3, activation='softmax')  # Output layer untuk binary classification\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4880b-4c3f-489a-8690-c10f984413ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# class myCallback(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         logs = logs or {}\n",
    "#         accuracy = logs.get('accuracy')\n",
    "#         val_accuracy = logs.get('val_accuracy')\n",
    "#         val_loss = logs.get('val_loss')\n",
    "        \n",
    "#         if accuracy is not None and val_accuracy is not None and val_loss is not None:\n",
    "#             if accuracy > 0.95 and val_accuracy > 0.95 and val_loss < 0.30:\n",
    "#                 print(f\"Stopping early at epoch {epoch+1}!\")\n",
    "#                 self.model.stop_training = True\n",
    "\n",
    "# callback = myCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f5cd8-183a-4a83-81c1-93f2dd17fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kompilasi model\n",
    "# # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Learning rate yang sedikit lebih tinggi\n",
    "# #               loss='categorical_crossentropy',\n",
    "# #               metrics=['accuracy'])\n",
    "# # model.summary()\n",
    "\n",
    "# model.compile(optimizer = 'adam', \n",
    "#               loss = 'categorical_crossentropy',\n",
    "#               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab93d0a-ed25-4bd3-b9da-070d17417168",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Learning rate yang sedikit lebih tinggi\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a4505-4b07-45db-9a91-cf7259265821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Menyusun model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Learning rate yang sedikit lebih tinggi\n",
    "              loss='categorical_crossentropy',  # Menggunakan categorical_crossentropy untuk lebih dari 2 kelas\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Menampilkan summary model\n",
    "model.summary()\n",
    "\n",
    "# Callback EarlyStopping untuk menghentikan pelatihan jika tidak ada perbaikan\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training model dengan data augmentation tanpa workers\n",
    "history = model.fit(\n",
    "    train_data,  # Data latih\n",
    "    validation_data=val_data,  # Data validasi\n",
    "    epochs=50,  # Jumlah epoch\n",
    "    steps_per_epoch=train_data.samples // batch_size,  # Menghitung jumlah langkah per epoch\n",
    "    validation_steps=val_data.samples // batch_size,  # Menghitung langkah validasi\n",
    "    callbacks=[early_stopping]  # Menambahkan callback EarlyStopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cdabd-0391-4dae-aa92-c6d6304940ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
